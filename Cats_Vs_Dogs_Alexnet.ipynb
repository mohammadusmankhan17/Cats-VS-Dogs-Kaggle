{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cats Vs Dogs Alexnet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBTdvf5Fzcrb",
        "outputId": "dd0a9172-c40f-4a42-a82a-d309ecf9c742"
      },
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 25 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 48.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 55.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.39.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.37.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.6.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=80207d97d831e469b50e5bf92f96e1b84eb5aef02c1301b2fb50713aff82fe24\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.6.0\n",
            "    Uninstalling tensorboard-2.6.0:\n",
            "      Successfully uninstalled tensorboard-2.6.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.0\n",
            "    Uninstalling tensorflow-2.6.0:\n",
            "      Successfully uninstalled tensorflow-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_9rjpDgznK9",
        "outputId": "f265096d-9d5f-4a81-dfce-8025e70ef12b"
      },
      "source": [
        "!pip install keras==2.0.8"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.0.8\n",
            "  Downloading Keras-2.0.8-py2.py3-none-any.whl (276 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 36.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 71 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 102 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 122 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 133 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 143 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 153 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 174 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 184 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 194 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 204 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 225 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 235 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 245 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 256 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 266 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.4.1)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.6.0\n",
            "    Uninstalling keras-2.6.0:\n",
            "      Successfully uninstalled keras-2.6.0\n",
            "Successfully installed keras-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy6H8i6N4fIB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKDK2CbdzMbg",
        "outputId": "23816c58-eeea-43b3-ac4f-dbe6df1be10a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Lh2D2PuLzZc8",
        "outputId": "5bd967e2-e162-42e0-b710-4f846be52295"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-789c9e10-88df-4d07-b136-804c3fa1f804\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-789c9e10-88df-4d07-b136-804c3fa1f804\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Saving dogs_vs_cats_config.py to dogs_vs_cats_config.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J1cSu0Yzckj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZplYyPIzhi4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-rVLzVazhu_"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWHoWA04zslt"
      },
      "source": [
        "Image To Array Preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXeTJNMXzv9c",
        "outputId": "654bff16-3b39-4f58-c261-119a0a479c6b"
      },
      "source": [
        "# import packages\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "class ImageToArrayPreprocessor:\n",
        "\t\n",
        "\tdef __init__(self, dataFormat=None):\n",
        "\t\t# store the image data format\n",
        "\t\tself.dataFormat = dataFormat\n",
        "\n",
        "\tdef preprocess(self, image):\n",
        "\t\t# apply the Keras utility function that correctly rearranges\n",
        "\t\t# the dimensions of the image\n",
        "\t\treturn img_to_array(image, data_format=self.dataFormat)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9obrXuAz8hu"
      },
      "source": [
        "Simple Preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oZcHXC3z7e8"
      },
      "source": [
        "# import packages\n",
        "import cv2\n",
        "\n",
        "class SimplePreprocessor:\n",
        "\n",
        "    def __init__(self, width, height, inter = cv2.INTER_AREA):\n",
        "        # store the target image width, height and interpolation\n",
        "        # method for resizing\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.inter = inter\n",
        "\n",
        "    def preprocess(self, image):\n",
        "        # resize the image to a fixed size\n",
        "        # ignore the aspect ratio\n",
        "        return cv2.resize(image, (self.width, self.height), interpolation = self.inter)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjP6Gmde0GVD"
      },
      "source": [
        "Patch Preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5xb2ZNS0J8y"
      },
      "source": [
        "# import packages\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "\n",
        "class PatchPreprocessor:\n",
        "\n",
        "    def __init__(self, width, height):\n",
        "        # store the target width and height of the image\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "\n",
        "    def preprocess(self, image):\n",
        "        # extract a random crop from the image with the target width and height\n",
        "        return extract_patches_2d(image, (self.height, self.width), max_patches = 1)[0]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNcN1prZ0SwF"
      },
      "source": [
        " Mean Preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXZeiglS0PBj"
      },
      "source": [
        "# import packages\n",
        "import cv2\n",
        "\n",
        "class MeanPreprocessor:\n",
        "\n",
        "    def __init__(self, rMean, gMean, bMean):\n",
        "        # store the Red, Green, and Blue channel average across a training set\n",
        "        self.rMean = rMean\n",
        "        self.gMean = gMean\n",
        "        self.bMean = bMean\n",
        "\n",
        "    def preprocess(self, image):\n",
        "        # split the image into its repsective Red, Green, and Blue\n",
        "        (B, G, R) = cv2.split(image.astype(\"float32\"))\n",
        "\n",
        "        # substract the means for each channel\n",
        "        R -= self.rMean\n",
        "        G -= self.gMean\n",
        "        B -= self.bMean\n",
        "\n",
        "        # merge the channels back together and return the image\n",
        "        return cv2.merge([B, G, R])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzjmyE8q0ZAB"
      },
      "source": [
        "Training Monitor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKiOrZ-F0cFK"
      },
      "source": [
        "# import packages\n",
        "from keras.callbacks import BaseLogger\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "\n",
        "class TrainingMonitor(BaseLogger):\n",
        "\n",
        "    def __init__(self, figPath, jsonPath = None, startAt = 0):\n",
        "        # store the output path for the figure , the path to the JSON\n",
        "        # serialized file, and the starting epoch\n",
        "        super(TrainingMonitor, self).__init__()\n",
        "        self.figPath = figPath\n",
        "        self.jsonPath = jsonPath\n",
        "        self.startAt = startAt\n",
        "\n",
        "    def on_train_begin(self, logs = {}):\n",
        "        # initialize the history dictionary\n",
        "        self.H = {}\n",
        "\n",
        "        # if the JSON history path exists, load the training history\n",
        "        if self.jsonPath is not None:\n",
        "            if os.path.exists(self.jsonPath):\n",
        "                self.H = json.loads(open(self.jsonPath).read())\n",
        "\n",
        "                # check to see if a starting epoch was supplied\n",
        "                if self.startAt > 0:\n",
        "                    # loop over the entries in the history log and\n",
        "                    # trim any entries that are past the starting epoch\n",
        "                    for k in self.H.keys():\n",
        "                        self.H[k] = self.H[k][:self.startAt]\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs = {}):\n",
        "        # loop over the logs and update the loss, accuracy, etc\n",
        "        # for the entire training process\n",
        "        for (k, v) in logs.items():\n",
        "            l = self.H.get(k, [])\n",
        "            l.append(v)\n",
        "            self.H[k] = l\n",
        "\n",
        "        # check to see if the training history should be serialized to file\n",
        "        if self.jsonPath is not None:\n",
        "            f = open(self.jsonPath, \"w\")\n",
        "            f.write(json.dumps(self.H))\n",
        "            f.close()\n",
        "\n",
        "        # ensure at least two epochs have passed before plotting\n",
        "        # (epoch starts at 0)\n",
        "        if len(self.H[\"loss\"]) > 1:\n",
        "            # plot the training loss and accuracy\n",
        "            N = np.arange(0, len(self.H[\"loss\"]))\n",
        "            plt.style.use(\"ggplot\")\n",
        "            plt.figure()\n",
        "            plt.plot(N, self.H[\"loss\"], label = \"train_loss\")\n",
        "            plt.plot(N, self.H[\"val_loss\"], label = \"val_loss\")\n",
        "            plt.plot(N, self.H[\"acc\"], label = \"train_acc\")\n",
        "            plt.plot(N, self.H[\"val_acc\"], label = \"val_acc\")\n",
        "            plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(len(self.H[\"loss\"])))\n",
        "            plt.xlabel(\"Epoch #\")\n",
        "            plt.ylabel(\"Loss/Accuracy\")\n",
        "            plt.legend()\n",
        "\n",
        "            # save the figure\n",
        "            plt.savefig(self.figPath)\n",
        "            plt.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmUn9f450lkE"
      },
      "source": [
        "HDF5 Dataset Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqP1rZYg0uFq"
      },
      "source": [
        "# import packages\n",
        "from keras.utils import np_utils\n",
        "# from tensorflow.keras import utils\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "class HDF5DatasetGenerator:\n",
        "\n",
        "    def __init__(self, dbPath, batchSize, preprocessors = None, aug = None,\n",
        "        binarize = True, classes = 2):\n",
        "        # store the batch size, preprocessors, and data augmentor, whether or not\n",
        "        # the labels should be binarized, along with the total number of classes\n",
        "        self.batchSize = batchSize\n",
        "        self.preprocessors = preprocessors\n",
        "        self.aug = aug\n",
        "        self.binarize = binarize\n",
        "        self.classes = classes\n",
        "\n",
        "        # open the HDF5 dataset for reading and determine the\n",
        "        # total number of entries in the database\n",
        "        self.db = h5py.File(dbPath)\n",
        "        self.numImages = self.db[\"labels\"].shape[0]\n",
        "\n",
        "    def generator(self, passes = np.inf):\n",
        "        # initialize the epoch count\n",
        "        epochs = 0\n",
        "\n",
        "        # keep looping infinitely -- the model will stop once we have\n",
        "        # reach the desired number of epochs\n",
        "        while epochs < passes:\n",
        "            # loop over the HDF5 dataset\n",
        "            for i in np.arange(0, self.numImages, self.batchSize):\n",
        "                # extract the images and labels from the HDF5 dataset\n",
        "                images = self.db[\"images\"][i : i + self.batchSize]\n",
        "                labels = self.db[\"labels\"][i : i + self.batchSize]\n",
        "\n",
        "                # check to see if the labels should be binarized\n",
        "                if self.binarize:\n",
        "                    labels = np_utils.to_categorical(labels, self.classes)\n",
        "\n",
        "                # check to see if our preprocessors are not None\n",
        "                if self.preprocessors is not None:\n",
        "                    # initialize the list of processed images\n",
        "                    procImages = []\n",
        "\n",
        "                    # loop over the images\n",
        "                    for image in images:\n",
        "                        # loop over the preprocessors and apply each to the image\n",
        "                        for p in self.preprocessors:\n",
        "                            image = p.preprocess(image)\n",
        "\n",
        "                        # update the list of preprocessed images\n",
        "                        procImages.append(image)\n",
        "\n",
        "                    # update the images array to be the processed images\n",
        "                    images = np.array(procImages)\n",
        "\n",
        "                # if the data augmentator exists, apply it\n",
        "                if self.aug is not None:\n",
        "                    (images, labels) = next(self.aug.flow(images, labels,\n",
        "                        batch_size = self.batchSize))\n",
        "\n",
        "                # yield a tuple of images and labels\n",
        "                yield (images, labels)\n",
        "\n",
        "            # increment the total number of epochs\n",
        "            epochs += 1\n",
        "\n",
        "    def close(self):\n",
        "        # close the database\n",
        "        self.db.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKGLswA8039l"
      },
      "source": [
        "AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs1xtL5Y04f-"
      },
      "source": [
        "# import packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "class AlexNet:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes, reg = 0.0002):\n",
        "        # initialize the model along with the input shape to be\n",
        "        # \"channels last\" and channels dimension itself\n",
        "        model = Sequential()\n",
        "        inputShape = (height, width, depth)\n",
        "        chanDim = -1\n",
        "\n",
        "        # if we are using \"channel first\", update the input shape\n",
        "        # and channels dimension\n",
        "        if K.image_data_format() == \"channels_first\":\n",
        "            inputShape = (depth, height, width)\n",
        "            chanDim = 1\n",
        "\n",
        "        # Block #1: first CONV => RELU => POOL layer set\n",
        "        model.add(Conv2D(96, (11, 11), strides = (4, 4), input_shape = inputShape,\n",
        "            padding = \"same\", kernel_regularizer = l2(reg)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis = chanDim))\n",
        "        model.add(MaxPooling2D(pool_size = (3, 3), strides = (2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        # Block #2 second CONV => RELU => POOL layer set\n",
        "        model.add(Conv2D(256, (5, 5), padding = \"same\", kernel_regularizer = l2(reg)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis = chanDim))\n",
        "        model.add(MaxPooling2D(pool_size = (3, 3), strides = (2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        # Block #3: 3 * (CONV = RELU) => POOL\n",
        "        model.add(Conv2D(384, (3, 3), padding = \"same\", kernel_regularizer = l2(reg)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis = chanDim))\n",
        "        model.add(Conv2D(384, (3, 3), padding = \"same\", kernel_regularizer = l2(reg)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis = chanDim))\n",
        "        model.add(Conv2D(256, (3, 3), padding = \"same\", kernel_regularizer = l2(reg)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis = chanDim))\n",
        "        model.add(MaxPooling2D(pool_size = (3, 3), strides = (2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        # Block #4: first FC => RELU layer set\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, kernel_regularizer = l2(reg)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        # Block #5: second FC => RELU layer set\n",
        "        model.add(Dense(4096, kernel_regularizer = l2(reg)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        # softmax classifiers\n",
        "        model.add(Dense(classes, kernel_regularizer = l2(reg)))\n",
        "        model.add(Activation(\"softmax\"))\n",
        "\n",
        "        # return the constructed network architecture\n",
        "        return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBg7DCBP1QOk"
      },
      "source": [
        "Train Alexnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xSnMmBy1S3w"
      },
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import packages\n",
        "import dogs_vs_cats_config as config\n",
        "# from pipeline.preprocessing import ImageToArrayPreprocessor\n",
        "# from pipeline.preprocessing import SimplePreprocessor\n",
        "# from pipeline.preprocessing import PatchPreprocessor\n",
        "# from pipeline.preprocessing import MeanPreprocessor\n",
        "# from pipeline.callbacks import TrainingMonitor\n",
        "# from pipeline.io import HDF5DatasetGenerator\n",
        "# from pipeline.nn.conv import AlexNet\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "import json\n",
        "import os\n",
        "\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range = 20, zoom_range = 0.15,\n",
        "    width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.15,\n",
        "    horizontal_flip = True, fill_mode = \"nearest\")\n",
        "\n",
        "# load the RGB means for the training set\n",
        "means = json.loads(open(config.DATASET_MEAN).read())\n",
        "\n",
        "# initialize the image preprocessors\n",
        "sp = SimplePreprocessor(227, 227)\n",
        "pp = PatchPreprocessor(227, 227)\n",
        "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
        "iap = ImageToArrayPreprocessor()\n",
        "\n",
        "# initialize the training and validation dataset generators\n",
        "trainGen = HDF5DatasetGenerator(config.TRAIN_HDF5, 128, aug = aug,\n",
        "    preprocessors = [pp, mp, iap], classes = 2)\n",
        "valGen = HDF5DatasetGenerator(config.VAL_HDF5, 128,\n",
        "    preprocessors = [sp, mp, iap], classes = 2)\n",
        "\n",
        "# initialize the optimizer\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr = 1e-3)\n",
        "model = AlexNet.build(width = 227, height = 227, depth = 3, classes = 2, reg = 0.0002)\n",
        "model.compile(loss = \"binary_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
        "\n",
        "# construct the set of callbacks\n",
        "path = os.path.sep.join([config.OUTPUT_PATH, \"{}.png\".format(os.getpid())])\n",
        "callbacks = [TrainingMonitor(path)]\n",
        "\n",
        "# train the network\n",
        "model.fit_generator(\n",
        "    trainGen.generator(),\n",
        "    steps_per_epoch = trainGen.numImages // 128,\n",
        "    validation_data = valGen.generator(),\n",
        "    validation_steps = valGen.numImages // 128,\n",
        "    epochs = 75,\n",
        "    max_queue_size = 10,\n",
        "    callbacks = callbacks, verbose = 1\n",
        ")\n",
        "\n",
        "# save the model to file\n",
        "print(\"[INFO] serializing model...\")\n",
        "model.save(config.MODEL_PATH, overwrite = True)\n",
        "\n",
        "# close the HDF5 dataset\n",
        "trainGen.close()\n",
        "valGen.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7y9o3D-45L-",
        "outputId": "73fb5a46-7a38-4d45-865f-c413d0052066"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('example.txt')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMXYCLQn4__9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}